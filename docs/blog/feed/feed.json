{
  "version": "https://jsonfeed.org/version/1",
  "title": "Yangyue&#39;s Blog",
  "home_page_url": "https://locke0.github.io/blog",
  "feed_url": "https://locke0.github.io/feed/feed.json",
  "description": "projects, ideas, solutions",
  "author": {
    "name": "Yangyue (Locke) Wang",
    "url": ""
  },
  "items": [{
      "id": "https://locke0.github.io/blog/posts/spike_gpt/",
      "url": "https://locke0.github.io/blog/posts/spike_gpt/",
      "title": "SpikeGPT Study Notes",
      "content_html": "<ul>\n<li>[ ] Compatibility between RWKV and LNNs? STDP and LNNs, SMiRL with LNNs?</li>\n</ul>\n<p>RWKV Unit with MatMul-free Language Model.</p>\n<p>RWKV unit can serve as an intermediate representation between contextual embedding model and the routine tracking layer?</p>\n<p>RWKV for Long-Range Routine Modeling and Context Integration</p>\n<ul>\n<li>Routine Recognition: Use RWKV to balance long-range dependencies in work sessions, capturing both immediate and past information for stable routine reinforcement?</li>\n<li>Surprise-Driven Memory Reset: In cases of significant deviation (high surprise), RWKV’s receptance mechanism can reset memory, allowing the system to learn new routines and detect emerging patterns?</li>\n</ul>\n<!-- !Research STDP and double check this -->\n<p>STDP adjusts weights based on the timing difference between pre-synaptic and post-synaptic spikes. To model this with LNNs, we can define a state-based palsticity rule that relies on time-based state adjustments rather than explicit weight updates.</p>\n<ol>\n<li>\n<p>Time-Based State Plasticity:</p>\n<ul>\n<li>\n<p>Define a time-based state $\\Delta h_t$ that responds to surprise, adjusting the state based on routine deviation.</p>\n</li>\n<li>\n<p>We can mimic the STDP process by making $\\Delta h_t$ a function of the surprise level $S$:</p>\n<p>$$\\Delta h_t = f(S) \\cdot (x_t - h_t)$$</p>\n</li>\n</ul>\n</li>\n<li>\n<p>Adaptive Routine Learning with Surprise Detection</p>\n</li>\n</ol>\n<ul>\n<li>When $S$ is low $\\rightarrow$ $h_t$ remains close to $x_t$, stabilizing the routine response</li>\n</ul>\n<p>Lessons for Spiking Neural Networks:</p>\n<ol>\n<li>Treating SNNs as state-space models: linear recurrence is critical</li>\n<li>Forget gates are essential for handling memory-limited state variables</li>\n</ol>\n<p>Lessons for Linear RNNs</p>\n<ol>\n<li>Static sparsity seems easier to deal with than dynamic sparsity</li>\n<li>Forget gates are eseential for handling memory-limited state variables</li>\n</ol>\n<p>LFMs</p>\n<ul>\n<li>Liquid Time-Constant Units</li>\n<li>Deep Signal Processing Layers - performs operations akin to Fourier Transforms and wavelet transforms, enabling hte model to capture frequency information effectively<br>\n$$[<br>\ny = F^{-1}(F(x) \\odot W)<br>\n]$$</li>\n</ul>\n<p>where ( F ) represents the Fourier transform, ( \\odot ) denotes element-wise multiplication, and ( W ) is a learnable weight matrix.</p>\n<p>State-Space Models</p>\n<ul>\n<li>State Transition Equations<br>\n$$[<br>\ns_t = f(s_{t-1}, x_t)<br>\n]$$</li>\n</ul>\n<p>Here, ( s_t ) is the state at time t, ( f ) is a function that updates the state given the previous state and current input, and ( x_t ) is the input at time t.</p>\n<ul>\n<li>Observation Equations<br>\n$$<br>\n[<br>\ny_t = g(s_t)<br>\n]<br>\n$$<br>\nHere, ( y_t ) is the observation at time t, and ( g ) is a function that maps the state to the output.</li>\n</ul>\n",
      "date_published": "2024-11-12T19:00:00-05:00"
    },{
      "id": "https://locke0.github.io/blog/posts/ebm_sn/",
      "url": "https://locke0.github.io/blog/posts/ebm_sn/",
      "title": "Composable Energy Based Models Study Notes",
      "content_html": "<ul>\n<li>[ ] Check EBM math</li>\n<li>[ ] Check training and sampling</li>\n<li>[ ] Check compositional modeling</li>\n<li>[ ] Explain MCMC</li>\n<li>[ ] Check applications</li>\n<li>[ ] Add sample code experiments</li>\n</ul>\n<h3 id=\"1-key-concepts\">1 Key Concepts</h3>\n<table>\n<thead>\n<tr>\n<th>Concept</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Energy Function</td>\n<td>A scalar function that assigns low values to likely configurations and high values to unlikely ones</td>\n</tr>\n<tr>\n<td>Partition Function</td>\n<td>Normalizing constant Z that ensures probability distribution sums/integrates to 1</td>\n</tr>\n<tr>\n<td>Gradient Descent</td>\n<td>Optimization method used to find local minima of energy function during inference</td>\n</tr>\n<tr>\n<td>MCMC</td>\n<td>Sampling method used to approximate expectations and generate samples from model</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"2-ebm-overview\">2 EBM Overview</h3>\n<p><mark>Energy based models</mark> predict compatibility between variable configurations rather than direct input-output mappings. The core idea is that energy functions assign low energy to likely configurations and high energy to unlikely ones.</p>\n<p>Compositional generation is a more tractable way to represent high dimensional distributions by modeling a set of simpler factors.</p>\n<p>e.g. have two models learn the 2 factors of the data distribution.</p>\n<p>Key features:</p>\n<ul>\n<li><strong><em>Implicit Generation</em></strong>: Sample generation via MCMC from energy function</li>\n<li><strong><em>Compositionality</em></strong>: Multiple energy functions can be combined</li>\n<li><strong><em>Flexibility</em></strong>: Can model diverse probability distributions and data types</li>\n</ul>\n<h3 id=\"3-energy-functions-%26-optimization\">3 Energy Functions &amp; Optimization</h3>\n<ol>\n<li>\n<p>Energy Function Mapping:</p>\n<ul>\n<li>Domain: Configurations in $\\mathcal{X} \\times \\mathcal{Y}$</li>\n<li>Range: Real numbers $\\mathbb{R}$</li>\n<li>Formal notation: $\\mathcal{F}: \\mathcal{X} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}$</li>\n</ul>\n</li>\n<li>\n<p>Prediction Process:</p>\n<ul>\n<li>Goal: Find minimum energy configurations</li>\n<li>Formula: $\\check{y} = \\arg\\min_y \\mathcal{F}(x,y)$</li>\n</ul>\n</li>\n<li>\n<p>Probability Connection:</p>\n<ul>\n<li>Via Boltzmann distribution</li>\n<li>Formula: $y \\sim p(x,y) \\propto e^{-E_{\\theta}(x,y)}$</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-latent-variable-models\">4 Latent Variable Models</h3>\n<p>Step 1: Joint Optimization</p>\n<ul>\n<li>Variables: z (latent), x (input), y (output)</li>\n<li>Formula: $\\check{y}, \\check{z} = \\arg\\min_{y,z} E(x,y,z)$</li>\n</ul>\n<p>Step 2: Free Energy Formulation</p>\n<ul>\n<li>Definition: $F_{\\beta}(x,y) = -\\frac{1}{\\beta} \\log \\int_z \\exp(-\\beta E(x,y,z))$</li>\n</ul>\n<p>Step 3: Limiting Behavior ($\\beta \\rightarrow \\infty$)</p>\n<ul>\n<li>Energy: $F_{\\infty}(x,y) = \\arg\\min_z E(x,y,z)$</li>\n<li>Prediction: $\\check{y} = \\arg\\min_y F(x,y)$</li>\n</ul>\n<h3 id=\"5-training-and-sampling\">5 Training and Sampling</h3>\n<p>You can use gradient of the funciton to guide the sampling process. However, this approach only allows you to sample a single probability mode rather than sampling from the probability distribution encoded by the energy function.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Formula</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NLL Loss</td>\n<td>$L_NLL(D) = E_z~D[E_{\\theta}(z)] + \\log \\int e^{-E_{\\theta}(z)} dz$</td>\n</tr>\n<tr>\n<td>Gradient</td>\n<td>$\\nabla_{\\theta} L_NLL(D) = E_z~D[\\nabla_{\\theta} E_{\\theta}(z)] - E_z~p_{\\theta}(z)[\\nabla_{\\theta} E_{\\theta}(z)]$</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"maximum-likelihood-training\">Maximum Likelihood Training</h4>\n<p>MLE objective:</p>\n<ul>\n<li>$L_NLL(D) = E_z~D[E_{\\theta}(z)] - E_z~p_{\\theta}(z)[E_{\\theta}(z)]$</li>\n</ul>\n<h4 id=\"langevin-dynamics-sampling\">Langevin Dynamics Sampling</h4>\n<p>Instead of using gradient descent to find the low energy point, we can use Langevin dynamics to sample from the energy landscape.</p>\n<p>Its iterative nature makes it slower than GANs or VAEs, but it can generalize to a new energy landscape.</p>\n<p>Update rule:</p>\n<ul>\n<li>$z_t = z_{t-1} - λ \\nabla_z E_{\\theta}(z_{t-1}) + \\sqrt{2λ} \\xi, \\xi \\sim N(0,1)$</li>\n</ul>\n<h4 id=\"learning-energy-functions\">Learning Energy Functions</h4>\n<ul>\n<li>[ ] Add the equation of gradient of MLE training for a point x here at 11:50</li>\n</ul>\n<p><a href=\"https://www.youtube.com/watch?v=kFchGKIrGzY\">https://www.youtube.com/watch?v=kFchGKIrGzY</a></p>\n<p><a href=\"https://atcold.github.io/NYU-DLSP20/en/week07/07-1/\">https://atcold.github.io/NYU-DLSP20/en/week07/07-1/</a></p>\n<h4 id=\"practical-considerations\">Practical Considerations</h4>\n<ul>\n<li>Use replay buffers to improve sample diversity</li>\n<li>Apply regularization to smooth energy landscapes</li>\n<li>Consider annealed landscapes for high-dimensional problems</li>\n</ul>\n<h3 id=\"6-compositional-modeling\">6 Compositional Modeling</h3>\n<h4 id=\"model-composition\">Model Composition</h4>\n<ul>\n<li>\n<p>Logical composition of energy landscapes</p>\n</li>\n<li>\n<p>Probability combinations via products and mixtures</p>\n</li>\n<li>\n<p>Hierarchical composition for complex tasks</p>\n</li>\n<li>\n<p>[ ] Add math for composition here</p>\n</li>\n</ul>\n<h3 id=\"7-applications\">7 Applications</h3>\n<ul>\n<li>Computer Vision: Scene understanding, image generation</li>\n<li>Robotics: Planning, constraint satisfaction</li>\n<li>Foundation Models: Vision-language tasks, hierarchical planning</li>\n<li>Scientific Applications: Inverse design, protein synthesis</li>\n</ul>\n<h4 id=\"diffusion-models\">Diffusion Models</h4>\n<h3 id=\"8-ebm-experiments\">8 EBM Experiments</h3>\n<h3 id=\"9-future-directions\">9 Future Directions</h3>\n<ul>\n<li>Scale to more complex data distributions</li>\n<li>Develop improved sampling techniques</li>\n<li>Expand applications in sciences and engineering</li>\n<li>Enhance zero-shot generalization capabilities</li>\n</ul>\n",
      "date_published": "2024-11-12T19:00:00-05:00"
    }
  ]
}
