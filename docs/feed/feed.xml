<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<title>Yangyue&#39;s Blog</title>
	<subtitle>Locke&#39;s projects</subtitle>
	
	<link href="https://locke0.github.io/blog/feed/feed.xml" rel="self"/>
	<link href="https://locke0.github.io/blog"/>
	<updated>2024-11-11T19:00:00-05:00</updated>
	<id>https://locke0.github.io/blog/posts</id>
	<author>
		<name>Yangyue (Locke) Wang</name>
		<email></email>
	</author>
	
	<entry>
		<title>Composable Energy Based Models Study Notes</title>
		<link href="https://locke0.github.io/blog/posts/ebm_sn/"/>
		<updated>2024-11-11T19:00:00-05:00</updated>
		<id>https://locke0.github.io/blog/posts/ebm_sn/</id>
		<content type="html">
		  &lt;h3 id=&quot;key-concepts&quot;&gt;Key Concepts&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Energy Function&lt;/td&gt;
&lt;td&gt;A scalar function that assigns low values to likely configurations and high values to unlikely ones&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Partition Function&lt;/td&gt;
&lt;td&gt;Normalizing constant Z that ensures probability distribution sums/integrates to 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient Descent&lt;/td&gt;
&lt;td&gt;Optimization method used to find local minima of energy function during inference&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MCMC&lt;/td&gt;
&lt;td&gt;Sampling method used to approximate expectations and generate samples from model&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;ebm-overview&quot;&gt;EBM Overview&lt;/h3&gt;
&lt;p&gt;&lt;mark&gt;Energy based models&lt;/mark&gt; predict compatibility between variable configurations rather than direct input-output mappings. The core idea is that energy functions assign low energy to likely configurations and high energy to unlikely ones.&lt;/p&gt;
&lt;p&gt;Key features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Implicit Generation&lt;/em&gt;&lt;/strong&gt;: Sample generation via MCMC from energy function&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Compositionality&lt;/em&gt;&lt;/strong&gt;: Multiple energy functions can be combined&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;Flexibility&lt;/em&gt;&lt;/strong&gt;: Can model diverse probability distributions and data types&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;math-foundations&quot;&gt;Math Foundations&lt;/h3&gt;
&lt;h4 id=&quot;energy-functions-and-probability&quot;&gt;Energy Functions and Probability&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Energy Function Mapping:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Domain: Configurations in $&#92;mathcal{X} &#92;times &#92;mathcal{Y}$&lt;/li&gt;
&lt;li&gt;Range: Real numbers $&#92;mathbb{R}$&lt;/li&gt;
&lt;li&gt;Formal notation: $&#92;mathcal{F}: &#92;mathcal{X} &#92;times &#92;mathcal{Y} &#92;rightarrow &#92;mathbb{R}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prediction Process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal: Find minimum energy configurations&lt;/li&gt;
&lt;li&gt;Formula: $&#92;check{y} = &#92;arg&#92;min_y &#92;mathcal{F}(x,y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Probability Connection:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Via Boltzmann distribution&lt;/li&gt;
&lt;li&gt;Formula: $y &#92;sim p(x,y) &#92;propto e^{-E_{&#92;theta}(x,y)}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;training-objectives&quot;&gt;Training Objectives&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Component&lt;/th&gt;
&lt;th&gt;Formula&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NLL Loss&lt;/td&gt;
&lt;td&gt;$L_NLL(D) = E_z~D[E_{&#92;theta}(z)] + &#92;log &#92;int e^{-E_{&#92;theta}(z)} dz$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient&lt;/td&gt;
&lt;td&gt;$&#92;nabla_{&#92;theta} L_NLL(D) = E_z~D[&#92;nabla_{&#92;theta} E_{&#92;theta}(z)] - E_z~p_{&#92;theta}(z)[&#92;nabla_{&#92;theta} E_{&#92;theta}(z)]$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;latent-variable-models&quot;&gt;Latent Variable Models&lt;/h3&gt;
&lt;p&gt;Step 1: Joint Optimization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Variables: z (latent), x (input), y (output)&lt;/li&gt;
&lt;li&gt;Formula: $&#92;check{y}, &#92;check{z} = &#92;arg&#92;min_{y,z} E(x,y,z)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Step 2: Free Energy Formulation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Definition: $F_{&#92;beta}(x,y) = -&#92;frac{1}{&#92;beta} &#92;log &#92;int_z &#92;exp(-&#92;beta E(x,y,z))$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Step 3: Limiting Behavior ($&#92;beta &#92;rightarrow &#92;infty$)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Energy: $F_{&#92;infty}(x,y) = &#92;arg&#92;min_z E(x,y,z)$&lt;/li&gt;
&lt;li&gt;Prediction: $&#92;check{y} = &#92;arg&#92;min_y F(x,y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;training-and-sampling&quot;&gt;Training and Sampling&lt;/h3&gt;
&lt;h4 id=&quot;maximum-likelihood-training&quot;&gt;Maximum Likelihood Training&lt;/h4&gt;
&lt;p&gt;MLE objective:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$L_NLL(D) = E_z~D[E_{&#92;theta}(z)] - E_z~p_{&#92;theta}(z)[E_{&#92;theta}(z)]$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;langevin-dynamics-sampling&quot;&gt;Langevin Dynamics Sampling&lt;/h4&gt;
&lt;p&gt;Update rule:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$z_t = z_{t-1} - λ &#92;nabla_z E_{&#92;theta}(z_{t-1}) + &#92;sqrt{2λ} &#92;xi, &#92;xi &#92;sim N(0,1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;practical-considerations&quot;&gt;Practical Considerations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Use replay buffers to improve sample diversity&lt;/li&gt;
&lt;li&gt;Apply regularization to smooth energy landscapes&lt;/li&gt;
&lt;li&gt;Consider annealed landscapes for high-dimensional problems&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;compositional-modeling&quot;&gt;Compositional Modeling&lt;/h3&gt;
&lt;h4 id=&quot;model-composition&quot;&gt;Model Composition&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Logical composition of energy landscapes&lt;/li&gt;
&lt;li&gt;Probability combinations via products and mixtures&lt;/li&gt;
&lt;li&gt;Hierarchical composition for complex tasks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;applications&quot;&gt;Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Computer Vision: Scene understanding, image generation&lt;/li&gt;
&lt;li&gt;Robotics: Planning, constraint satisfaction&lt;/li&gt;
&lt;li&gt;Foundation Models: Vision-language tasks, hierarchical planning&lt;/li&gt;
&lt;li&gt;Scientific Applications: Inverse design, protein synthesis&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;future-directions&quot;&gt;Future Directions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Scale to more complex data distributions&lt;/li&gt;
&lt;li&gt;Develop improved sampling techniques&lt;/li&gt;
&lt;li&gt;Expand applications in sciences and engineering&lt;/li&gt;
&lt;li&gt;Enhance zero-shot generalization capabilities&lt;/li&gt;
&lt;/ul&gt;

			
		</content>
	</entry>
</feed>
